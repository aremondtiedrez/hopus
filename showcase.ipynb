{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad85b80b-8647-4d08-aff5-4d6a309c641d",
      "metadata": {
        "id": "ad85b80b-8647-4d08-aff5-4d6a309c641d"
      },
      "source": [
        "# HOPUS\n",
        "\n",
        "HOPUS (**HO**using **P**ricing **U**tilitie**S**) contains a variety of routines used to predict real estate prices.\n",
        "\n",
        "This notebook highlights what HOPUS can do, namely\n",
        "- clean the raw data,\n",
        "- train a variety of models for the prediction of real estate prices, and\n",
        "- evaluate the performance of these models."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Technical preliminaries"
      ],
      "metadata": {
        "id": "OEM9gL75m7Kt"
      },
      "id": "OEM9gL75m7Kt"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b98883a3-1533-4380-a6d1-03f601619bfe",
      "metadata": {
        "id": "b98883a3-1533-4380-a6d1-03f601619bfe",
        "outputId": "be5c9b0b-e83a-43a1-b444-968660d777a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hopus'...\n",
            "remote: Enumerating objects: 313, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 313 (delta 64), reused 44 (delta 17), pack-reused 204 (from 1)\u001b[K\n",
            "Receiving objects: 100% (313/313), 769.88 KiB | 3.61 MiB/s, done.\n",
            "Resolving deltas: 100% (173/173), done.\n",
            "/content/hopus\n"
          ]
        }
      ],
      "source": [
        "# We clone the HOPUS repository to have access to all its data and routines\n",
        "!git clone https://github.com/aremondtiedrez/hopus.git\n",
        "%cd hopus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import requisite modules from HOPUS\n",
        "import evaluation\n",
        "import models\n",
        "import preprocessing"
      ],
      "metadata": {
        "id": "2XeVMFJapR22"
      },
      "id": "2XeVMFJapR22",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data cleaning"
      ],
      "metadata": {
        "id": "062YLELMkks7"
      },
      "id": "062YLELMkks7"
    },
    {
      "cell_type": "code",
      "source": [
        "hpi = preprocessing.home_price_index.load()\n",
        "preprocessing.home_price_index.preprocess(hpi)\n",
        "\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)"
      ],
      "metadata": {
        "id": "g5fCLFiKkm0x"
      },
      "id": "g5fCLFiKkm0x",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_rmse = evaluation.hpi_rmse(listings_data, target=\"price\")\n",
        "log_price_rmse = evaluation.hpi_rmse(listings_data, target=\"logPrice\")\n",
        "print(\n",
        "    \"When using the available home price index\\n\"\n",
        "    \"instead of the true home price index,\\n\"\n",
        "    f\"the price RMSE is ${price_rmse/1_000:.0f}k and \\n\"\n",
        "    f\"the log-price RMSE is {log_price_rmse:.3f}.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfFHEMBmlzEq",
        "outputId": "a2c920cc-d7e5-4ce5-c3a0-3bb57c9e7b59"
      },
      "id": "qfFHEMBmlzEq",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When using the available home price index\n",
            "instead of the true home price index,\n",
            "the price RMSE is $10k and \n",
            "the log-price RMSE is 0.021.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model\n",
        "Average (time-normalized) price-per-square-foot over each ZIP code"
      ],
      "metadata": {
        "id": "CJ10nY4KKs_d"
      },
      "id": "CJ10nY4KKs_d"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets"
      ],
      "metadata": {
        "id": "-wKqpNK-K3k2"
      },
      "id": "-wKqpNK-K3k2",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Baseline()\n",
        "model.fit(listings_data, None)\n",
        "train_mse = model.evaluate(listings_data, listings_data[\"price\"])\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "print(f\"Training error: ${train_rmse / 1_000:.3f}k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tokBPzGDULm-",
        "outputId": "7a233cbb-2300-440c-fa22-ea6d7e8c4d4c"
      },
      "id": "tokBPzGDULm-",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training error: $157.830k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = secrets.randbits(32)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.Baseline, listings_data, listings_data[\"price\"], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "# Report evaluations\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3NsDz0VaXOm",
        "outputId": "0242036f-6824-4f1e-f41c-1bf1f99404b0"
      },
      "id": "_3NsDz0VaXOm",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation training error: $158k\n",
            "Cross-validation test error:     $159k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Technical preliminary (before linear regression or XGBoost)\n",
        "We group the columns into key features, auxiliary features, and target\n",
        "(as well as into information columns and unused columns)."
      ],
      "metadata": {
        "id": "NaNmqrnQT6Y-"
      },
      "id": "NaNmqrnQT6Y-"
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing.property_listings.group_columns(listings_data)"
      ],
      "metadata": {
        "id": "jFKNTHRlT6sr"
      },
      "id": "jFKNTHRlT6sr",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression: training and evaluation"
      ],
      "metadata": {
        "id": "x67uIijqBxQu"
      },
      "id": "x67uIijqBxQu"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "oMJRfFuNf2Nd"
      },
      "id": "oMJRfFuNf2Nd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = secrets.randbits(32)\n",
        "\n",
        "# Train-test split\n",
        "train_features, test_features = train_test_split(listings_data[\"keyPredictionFeatures\"], train_size=0.8, shuffle=True, random_state=seed)\n",
        "train_target, test_target = train_test_split(listings_data[(\"target\", \"price\")], train_size=0.8, shuffle=True, random_state=seed)\n",
        "\n",
        "# Train model\n",
        "model = models.LinearRegression()\n",
        "model.fit(train_features, train_target)\n",
        "\n",
        "# Evaluate model\n",
        "train_rmse = np.sqrt(model.evaluate(train_features, train_target))\n",
        "test_rmse = np.sqrt(model.evaluate(test_features, test_target))\n",
        "\n",
        "# Report evaluations\n",
        "print(f\"Seed: {seed}\")\n",
        "print(f\"Training error: ${train_rmse / 1_000:.3f}k\")\n",
        "print(f\"Test error:     ${test_rmse / 1_000:.3f}k\")"
      ],
      "metadata": {
        "id": "dsdAoBR5B-WZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a14277-02d6-4fc8-cbf6-99f9404aeb3f"
      },
      "id": "dsdAoBR5B-WZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed: 1480318944\n",
            "Training error: $161.367k\n",
            "Test error:     $137.479k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression: evaluation with cross-validation"
      ],
      "metadata": {
        "id": "IJOAf4QFMzcm"
      },
      "id": "IJOAf4QFMzcm"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets"
      ],
      "metadata": {
        "id": "5xdVLh7KM3H5"
      },
      "id": "5xdVLh7KM3H5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = secrets.randbits(32)\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "# Report evaluations\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd-OyngegV2O",
        "outputId": "14bea77b-efb2-4a23-a8c6-e106ab9129a3"
      },
      "id": "kd-OyngegV2O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation training error: $156k\n",
            "Cross-validation test error:     $159k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression: cross-validation for various data subsets"
      ],
      "metadata": {
        "id": "PUmaN8fUjznV"
      },
      "id": "PUmaN8fUjznV"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets"
      ],
      "metadata": {
        "id": "1mKIViookDAq"
      },
      "id": "1mKIViookDAq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = secrets.randbits(32)"
      ],
      "metadata": {
        "id": "tuSVNuXoqcZy"
      },
      "id": "tuSVNuXoqcZy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# PART A: USING ONLY THE KEY PREDICTION FEATURES\n",
        "# --------------------------------------------------\n",
        "\n",
        "# Case 1: with outliers and imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "#preprocessing.property_listings.drop_outliers(listings_data)\n",
        "#preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"With outliers and with imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 2: without outliers but with imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "#preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Without outliers but with imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 3: with outliers but without imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "#preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"With outliers but without imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 1: without outliers nor imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Without outliers nor imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "id": "3XfrBstwjzCl",
        "outputId": "971230cc-e0ab-4590-8a44-063a882539b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3XfrBstwjzCl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "With outliers and with imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $248k\n",
            "Cross-validation test error:     $252k\n",
            "--------------------------------------------------\n",
            "Without outliers but with imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $163k\n",
            "Cross-validation test error:     $167k\n",
            "--------------------------------------------------\n",
            "With outliers but without imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $240k\n",
            "Cross-validation test error:     $244k\n",
            "--------------------------------------------------\n",
            "Without outliers nor imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $156k\n",
            "Cross-validation test error:     $160k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# PART B: USING THE KEY AND THE AUXILIARY PREDICTION FEATURES\n",
        "# ------------------------------------------------------------\n",
        "features_label = [\"keyPredictionFeatures\", \"auxiliaryPredictionFeatures\"]\n",
        "\n",
        "# Case 1: with outliers and imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "#preprocessing.property_listings.drop_outliers(listings_data)\n",
        "#preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[features_label], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"With outliers and with imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 2: without outliers but with imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "#preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[features_label], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Without outliers but with imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 3: with outliers but without imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "#preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[features_label], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"With outliers but without imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 1: without outliers nor imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[features_label], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Without outliers nor imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "id": "kW4SSYAvqhnc",
        "outputId": "0548d384-6bdd-4456-a0be-0d06b14190c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kW4SSYAvqhnc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "With outliers and with imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $230k\n",
            "Cross-validation test error:     $248k\n",
            "--------------------------------------------------\n",
            "Without outliers but with imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $144k\n",
            "Cross-validation test error:     $161k\n",
            "--------------------------------------------------\n",
            "With outliers but without imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $227k\n",
            "Cross-validation test error:     $240k\n",
            "--------------------------------------------------\n",
            "Without outliers nor imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $138k\n",
            "Cross-validation test error:     $151k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost: training and cross-validation"
      ],
      "metadata": {
        "id": "ie8WmxhcGWsC"
      },
      "id": "ie8WmxhcGWsC"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets"
      ],
      "metadata": {
        "id": "js4fCZ0PGxwi"
      },
      "id": "js4fCZ0PGxwi",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = listings_data[[\"keyPredictionFeatures\", \"auxiliaryPredictionFeatures\"]]\n",
        "target = listings_data[(\"target\", \"price\")]\n",
        "\n",
        "hyperparameters = {\n",
        "    \"max_depth\": 5,\n",
        "    \"min_child_weight\": 1,\n",
        "    \"gamma\": 0,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"scale_pos_weight\": 1\n",
        "}\n",
        "\n",
        "model = models.BoostedTrees(**hyperparameters)\n",
        "model.fit(features, target)\n",
        "train_rmse = np.sqrt(model.evaluate(features, target))\n",
        "print(f\"Training error: ${train_rmse / 1_000:.3f}k\")"
      ],
      "metadata": {
        "id": "6l7M4opgQvFs",
        "outputId": "8758c2b9-df5a-4015-9e65-0274b47c76dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6l7M4opgQvFs",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training error: $27.750k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {\n",
        "    \"max_depth\": 5,\n",
        "    \"min_child_weight\": 1,\n",
        "    \"gamma\": 0,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"scale_pos_weight\": 1\n",
        "}\n",
        "\n",
        "seed = secrets.randbits(32)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.BoostedTrees, features, target, 100, seed, hyperparameters=hyperparameters)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "# Report evaluations\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "id": "x8ahXVlTRPNe",
        "outputId": "8d8a3d33-7261-457a-ef4d-abbe446a8fc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "x8ahXVlTRPNe",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation training error: $26k\n",
            "Cross-validation test error:     $127k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost: Hierarchical hyperparameter search"
      ],
      "metadata": {
        "id": "H_uZoVd1cbE9"
      },
      "id": "H_uZoVd1cbE9"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import secrets"
      ],
      "metadata": {
        "id": "BdVaRTRacugV"
      },
      "id": "BdVaRTRacugV",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1\n",
        "# We use sensible default choices and aim to find a good number of estimators to use\n",
        "hyperparameters = {\n",
        "    \"max_depth\": 5,\n",
        "    \"min_child_weight\": 1,\n",
        "    \"gamma\": 0,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"scale_pos_weight\": 1,\n",
        "    \"learning_rate\": 0.1\n",
        "}\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"seed\": None,\n",
        "    \"n_splits\": 50,\n",
        "}\n",
        "\n",
        "experiment_records = []\n",
        "n_experiments = 4\n",
        "# START - HYPERPARAMETER-DEPENDENT SECTION\n",
        "for n_estimators in (10, 30, 100, 300, 1000):\n",
        "    hyperparameters[\"n_estimators\"] = n_estimators\n",
        "# END - HYPERPARAMETER-DEPENDENT SECTION\n",
        "    for _ in range(n_experiments):\n",
        "        experiment_parameters[\"seed\"] = secrets.randbits(32)\n",
        "        train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.BoostedTrees, features, target, **experiment_parameters, hyperparameters=hyperparameters)\n",
        "        experiment_result = {\n",
        "            \"train_cv_mse\": train_cv_mse,\n",
        "            \"test_cv_mse\": test_cv_mse,\n",
        "        }\n",
        "        record = {\n",
        "            **experiment_parameters,\n",
        "            **hyperparameters,\n",
        "            **experiment_result,\n",
        "        }\n",
        "        experiment_records.append(record)\n",
        "\n",
        "experiment_records = pd.DataFrame(experiment_records)"
      ],
      "metadata": {
        "id": "vsAHOwIKcdcK"
      },
      "id": "vsAHOwIKcdcK",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the RMSE for each set of hyperparameters (here, only the value of `n_estimators` changes)\n",
        "np.sqrt(experiment_records.groupby(list(hyperparameters.keys()))[\"test_cv_mse\"].mean())"
      ],
      "metadata": {
        "id": "lExFeKk-ctDe",
        "outputId": "7750ec90-26cf-43be-cd20-d5a37953dc28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "id": "lExFeKk-ctDe",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "max_depth  min_child_weight  gamma  subsample  colsample_bytree  scale_pos_weight  learning_rate  n_estimators\n",
              "5          1                 0      0.8        0.8               1                 0.1            10              165328.884302\n",
              "                                                                                                  30              133277.373184\n",
              "                                                                                                  100             125176.910132\n",
              "                                                                                                  300             125621.217459\n",
              "                                                                                                  1000            125821.204287\n",
              "Name: test_cv_mse, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>test_cv_mse</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_child_weight</th>\n",
              "      <th>gamma</th>\n",
              "      <th>subsample</th>\n",
              "      <th>colsample_bytree</th>\n",
              "      <th>scale_pos_weight</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>n_estimators</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">0.8</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">0.8</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">0.1</th>\n",
              "      <th>10</th>\n",
              "      <td>165328.884302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>133277.373184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>125176.910132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>125621.217459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>125821.204287</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}