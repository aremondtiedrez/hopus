{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad85b80b-8647-4d08-aff5-4d6a309c641d",
      "metadata": {
        "id": "ad85b80b-8647-4d08-aff5-4d6a309c641d"
      },
      "source": [
        "# HOPUS\n",
        "\n",
        "HOPUS (**HO**using **P**ricing **U**tilitie**S**) contains a variety of routines used to predict real estate prices.\n",
        "\n",
        "This notebook highlights what HOPUS can do, namely\n",
        "- clean the raw data,\n",
        "- train a variety of models for the prediction of real estate prices, and\n",
        "- evaluate the performance of these models."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Technical preliminaries"
      ],
      "metadata": {
        "id": "OEM9gL75m7Kt"
      },
      "id": "OEM9gL75m7Kt"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b98883a3-1533-4380-a6d1-03f601619bfe",
      "metadata": {
        "id": "b98883a3-1533-4380-a6d1-03f601619bfe",
        "outputId": "43a6bb5d-9231-4541-ec03-0116bfbcadc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'hopus' already exists and is not an empty directory.\n",
            "/content/hopus\n"
          ]
        }
      ],
      "source": [
        "# We clone the HOPUS repository to have access to all its data and routines\n",
        "!git clone https://github.com/aremondtiedrez/hopus.git\n",
        "%cd hopus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import requisite modules from HOPUS\n",
        "import evaluation\n",
        "import models\n",
        "import preprocessing"
      ],
      "metadata": {
        "id": "2XeVMFJapR22"
      },
      "id": "2XeVMFJapR22",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data cleaning"
      ],
      "metadata": {
        "id": "062YLELMkks7"
      },
      "id": "062YLELMkks7"
    },
    {
      "cell_type": "code",
      "source": [
        "hpi = preprocessing.home_price_index.load()\n",
        "preprocessing.home_price_index.preprocess(hpi)\n",
        "\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)"
      ],
      "metadata": {
        "id": "g5fCLFiKkm0x"
      },
      "id": "g5fCLFiKkm0x",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_rmse = evaluation.hpi_rmse(listings_data, target=\"price\")\n",
        "log_price_rmse = evaluation.hpi_rmse(listings_data, target=\"logPrice\")\n",
        "print(\n",
        "    \"When using the available home price index\\n\"\n",
        "    \"instead of the true home price index,\\n\"\n",
        "    f\"the price RMSE is ${price_rmse/1_000:.0f}k and \\n\"\n",
        "    f\"the log-price RMSE is {log_price_rmse:.3f}.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfFHEMBmlzEq",
        "outputId": "ab0a7e73-096e-4be4-f6a9-3e9bb12307a4"
      },
      "id": "qfFHEMBmlzEq",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When using the available home price index\n",
            "instead of the true home price index,\n",
            "the price RMSE is $10k and \n",
            "the log-price RMSE is 0.021.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model\n",
        "Average (time-normalized) price-per-square-foot over each ZIP code"
      ],
      "metadata": {
        "id": "CJ10nY4KKs_d"
      },
      "id": "CJ10nY4KKs_d"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets"
      ],
      "metadata": {
        "id": "-wKqpNK-K3k2"
      },
      "id": "-wKqpNK-K3k2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Baseline()\n",
        "model.fit(listings_data, None)\n",
        "train_mse = model.evaluate(listings_data, listings_data[\"price\"])\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "print(f\"Training error: ${train_rmse / 1_000:.3f}k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tokBPzGDULm-",
        "outputId": "7a233cbb-2300-440c-fa22-ea6d7e8c4d4c"
      },
      "id": "tokBPzGDULm-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training error: $157.830k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = secrets.randbits(32)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.Baseline, listings_data, listings_data[\"price\"], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "# Report evaluations\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3NsDz0VaXOm",
        "outputId": "0242036f-6824-4f1e-f41c-1bf1f99404b0"
      },
      "id": "_3NsDz0VaXOm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation training error: $158k\n",
            "Cross-validation test error:     $159k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Technical preliminary (before linear regression or XGBoost)\n",
        "We group the columns into key features, auxiliary features, and target\n",
        "(as well as into information columns and unused columns)."
      ],
      "metadata": {
        "id": "NaNmqrnQT6Y-"
      },
      "id": "NaNmqrnQT6Y-"
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing.property_listings.group_columns(listings_data)"
      ],
      "metadata": {
        "id": "jFKNTHRlT6sr"
      },
      "id": "jFKNTHRlT6sr",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression: training and evaluation"
      ],
      "metadata": {
        "id": "x67uIijqBxQu"
      },
      "id": "x67uIijqBxQu"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "oMJRfFuNf2Nd"
      },
      "id": "oMJRfFuNf2Nd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = secrets.randbits(32)\n",
        "\n",
        "# Train-test split\n",
        "train_features, test_features = train_test_split(listings_data[\"keyPredictionFeatures\"], train_size=0.8, shuffle=True, random_state=seed)\n",
        "train_target, test_target = train_test_split(listings_data[(\"target\", \"price\")], train_size=0.8, shuffle=True, random_state=seed)\n",
        "\n",
        "# Train model\n",
        "model = models.LinearRegression()\n",
        "model.fit(train_features, train_target)\n",
        "\n",
        "# Evaluate model\n",
        "train_rmse = np.sqrt(model.evaluate(train_features, train_target))\n",
        "test_rmse = np.sqrt(model.evaluate(test_features, test_target))\n",
        "\n",
        "# Report evaluations\n",
        "print(f\"Seed: {seed}\")\n",
        "print(f\"Training error: ${train_rmse / 1_000:.3f}k\")\n",
        "print(f\"Test error:     ${test_rmse / 1_000:.3f}k\")"
      ],
      "metadata": {
        "id": "dsdAoBR5B-WZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a14277-02d6-4fc8-cbf6-99f9404aeb3f"
      },
      "id": "dsdAoBR5B-WZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed: 1480318944\n",
            "Training error: $161.367k\n",
            "Test error:     $137.479k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression: evaluation with cross-validation"
      ],
      "metadata": {
        "id": "IJOAf4QFMzcm"
      },
      "id": "IJOAf4QFMzcm"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets"
      ],
      "metadata": {
        "id": "5xdVLh7KM3H5"
      },
      "id": "5xdVLh7KM3H5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = secrets.randbits(32)\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "# Report evaluations\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd-OyngegV2O",
        "outputId": "14bea77b-efb2-4a23-a8c6-e106ab9129a3"
      },
      "id": "kd-OyngegV2O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation training error: $156k\n",
            "Cross-validation test error:     $159k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression: cross-validation for various data subsets"
      ],
      "metadata": {
        "id": "PUmaN8fUjznV"
      },
      "id": "PUmaN8fUjznV"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets"
      ],
      "metadata": {
        "id": "1mKIViookDAq"
      },
      "id": "1mKIViookDAq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = secrets.randbits(32)"
      ],
      "metadata": {
        "id": "tuSVNuXoqcZy"
      },
      "id": "tuSVNuXoqcZy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# PART A: USING ONLY THE KEY PREDICTION FEATURES\n",
        "# --------------------------------------------------\n",
        "\n",
        "# Case 1: with outliers and imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "#preprocessing.property_listings.drop_outliers(listings_data)\n",
        "#preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"With outliers and with imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 2: without outliers but with imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "#preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Without outliers but with imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 3: with outliers but without imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "#preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"With outliers but without imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 1: without outliers nor imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Without outliers nor imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "id": "3XfrBstwjzCl",
        "outputId": "971230cc-e0ab-4590-8a44-063a882539b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3XfrBstwjzCl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "With outliers and with imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $248k\n",
            "Cross-validation test error:     $252k\n",
            "--------------------------------------------------\n",
            "Without outliers but with imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $163k\n",
            "Cross-validation test error:     $167k\n",
            "--------------------------------------------------\n",
            "With outliers but without imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $240k\n",
            "Cross-validation test error:     $244k\n",
            "--------------------------------------------------\n",
            "Without outliers nor imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $156k\n",
            "Cross-validation test error:     $160k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# PART B: USING THE KEY AND THE AUXILIARY PREDICTION FEATURES\n",
        "# ------------------------------------------------------------\n",
        "features_label = [\"keyPredictionFeatures\", \"auxiliaryPredictionFeatures\"]\n",
        "\n",
        "# Case 1: with outliers and imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "#preprocessing.property_listings.drop_outliers(listings_data)\n",
        "#preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[features_label], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"With outliers and with imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 2: without outliers but with imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "#preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[features_label], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Without outliers but with imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 3: with outliers but without imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "#preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[features_label], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"With outliers but without imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 1: without outliers nor imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegression, listings_data[features_label], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Without outliers nor imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "id": "kW4SSYAvqhnc",
        "outputId": "0548d384-6bdd-4456-a0be-0d06b14190c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kW4SSYAvqhnc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "With outliers and with imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $230k\n",
            "Cross-validation test error:     $248k\n",
            "--------------------------------------------------\n",
            "Without outliers but with imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $144k\n",
            "Cross-validation test error:     $161k\n",
            "--------------------------------------------------\n",
            "With outliers but without imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $227k\n",
            "Cross-validation test error:     $240k\n",
            "--------------------------------------------------\n",
            "Without outliers nor imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $138k\n",
            "Cross-validation test error:     $151k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost: training and cross-validation"
      ],
      "metadata": {
        "id": "ie8WmxhcGWsC"
      },
      "id": "ie8WmxhcGWsC"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets"
      ],
      "metadata": {
        "id": "js4fCZ0PGxwi"
      },
      "id": "js4fCZ0PGxwi",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = listings_data[[\"keyPredictionFeatures\", \"auxiliaryPredictionFeatures\"]]\n",
        "target = listings_data[(\"target\", \"price\")]\n",
        "\n",
        "hyperparameters = {\n",
        "    \"max_depth\": 5,\n",
        "    \"min_child_weight\": 1,\n",
        "    \"gamma\": 0,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"scale_pos_weight\": 1\n",
        "}\n",
        "\n",
        "model = models.BoostedTrees(**hyperparameters)\n",
        "model.fit(features, target)\n",
        "train_rmse = np.sqrt(model.evaluate(features, target))\n",
        "print(f\"Training error: ${train_rmse / 1_000:.3f}k\")"
      ],
      "metadata": {
        "id": "6l7M4opgQvFs",
        "outputId": "a070c74d-6a3d-48a3-dbe2-55c34a08efe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6l7M4opgQvFs",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training error: $27.750k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {\n",
        "    \"max_depth\": 5,\n",
        "    \"min_child_weight\": 1,\n",
        "    \"gamma\": 0,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"scale_pos_weight\": 1\n",
        "}\n",
        "\n",
        "seed = secrets.randbits(32)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.BoostedTrees, features, target, 100, seed, hyperparameters=hyperparameters)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "# Report evaluations\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "id": "x8ahXVlTRPNe",
        "outputId": "badccd69-c9af-4662-ce00-c3187e97257a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "x8ahXVlTRPNe",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation training error: $26k\n",
            "Cross-validation test error:     $128k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost: Hierarchical hyperparameter search"
      ],
      "metadata": {
        "id": "H_uZoVd1cbE9"
      },
      "id": "H_uZoVd1cbE9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We follow the hierarchical hyperparameter search procedure described in\n",
        "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
      ],
      "metadata": {
        "id": "LjL5a6nKJHwc"
      },
      "id": "LjL5a6nKJHwc"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import secrets\n",
        "import time\n",
        "\n",
        "from itertools import product"
      ],
      "metadata": {
        "id": "BdVaRTRacugV"
      },
      "id": "BdVaRTRacugV",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: `n_estimators`"
      ],
      "metadata": {
        "id": "sGGd_rCfSJqi"
      },
      "id": "sGGd_rCfSJqi"
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1\n",
        "# We use sensible default choices and aim to find a good number of estimators to use\n",
        "hyperparameters = {\n",
        "    \"max_depth\": 5,\n",
        "    \"min_child_weight\": 1,\n",
        "    \"gamma\": 0,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"scale_pos_weight\": 1,\n",
        "    \"learning_rate\": 0.1\n",
        "}\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"seed\": None,\n",
        "    \"n_splits\": 5,\n",
        "}\n",
        "\n",
        "experiment_records = []\n",
        "n_experiments = 5\n",
        "start_time = time.time()\n",
        "# START - HYPERPARAMETER-DEPENDENT SECTION\n",
        "for n_estimators in (10, 30, 100, 300, 1000):\n",
        "    hyperparameters[\"n_estimators\"] = n_estimators\n",
        "# END - HYPERPARAMETER-DEPENDENT SECTION\n",
        "    for _ in range(n_experiments):\n",
        "        experiment_parameters[\"seed\"] = secrets.randbits(32)\n",
        "        train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.BoostedTrees, features, target, **experiment_parameters, hyperparameters=hyperparameters)\n",
        "        experiment_result = {\n",
        "            \"train_cv_mse\": train_cv_mse,\n",
        "            \"test_cv_mse\": test_cv_mse,\n",
        "        }\n",
        "        record = {\n",
        "            **experiment_parameters,\n",
        "            **hyperparameters,\n",
        "            **experiment_result,\n",
        "        }\n",
        "        experiment_records.append(record)\n",
        "end_time = time.time()\n",
        "print(f\"Duration of the experiment: {(end_time - start_time)/60:.1f} minutes.\")\n",
        "\n",
        "experiment_records = pd.DataFrame(experiment_records)"
      ],
      "metadata": {
        "id": "vsAHOwIKcdcK",
        "outputId": "dcdebff0-3994-49b6-d8cc-ddd0fc9a4fc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vsAHOwIKcdcK",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration of the experiment: 1.2 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the RMSE for each set of hyperparameters (here, only the value of `n_estimators` changes)\n",
        "np.sqrt(experiment_records.groupby(list(hyperparameters.keys()))[\"test_cv_mse\"].mean())"
      ],
      "metadata": {
        "id": "lExFeKk-ctDe",
        "outputId": "72d12cb3-d0dc-4797-db63-3bb9503fe9e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "id": "lExFeKk-ctDe",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "max_depth  min_child_weight  gamma  subsample  colsample_bytree  scale_pos_weight  learning_rate  n_estimators\n",
              "5          1                 0      0.8        0.8               1                 0.1            10              164188.656898\n",
              "                                                                                                  30              134271.585738\n",
              "                                                                                                  100             127132.624531\n",
              "                                                                                                  300             130599.472778\n",
              "                                                                                                  1000            133891.596128\n",
              "Name: test_cv_mse, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>test_cv_mse</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_child_weight</th>\n",
              "      <th>gamma</th>\n",
              "      <th>subsample</th>\n",
              "      <th>colsample_bytree</th>\n",
              "      <th>scale_pos_weight</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>n_estimators</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">0.8</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">0.8</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
              "      <th rowspan=\"5\" valign=\"top\">0.1</th>\n",
              "      <th>10</th>\n",
              "      <td>164188.656898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>134271.585738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>127132.624531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>130599.472778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>133891.596128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: `max_depth` and `min_child_weight`"
      ],
      "metadata": {
        "id": "sr6kB1DXSMc-"
      },
      "id": "sr6kB1DXSMc-"
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2\n",
        "# We fix `n_estimators = 300` from the previous step and\n",
        "# now seek to find good values for `max_depth` and `min_child_weight`.\n",
        "hyperparameters = {\n",
        "    \"n_estimators\": 100,\n",
        "    \"gamma\": 0,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"scale_pos_weight\": 1,\n",
        "    \"learning_rate\": 0.1\n",
        "}\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"seed\": None,\n",
        "    \"n_splits\": 5,\n",
        "}\n",
        "\n",
        "experiment_records = []\n",
        "n_experiments = 5\n",
        "start_time = time.time()\n",
        "# START - HYPERPARAMETER-DEPENDENT SECTION\n",
        "for max_depth, min_child_weight in product((3, 5, 7, 9), (1, 3, 5)):\n",
        "    hyperparameters[\"max_depth\"] = max_depth\n",
        "    hyperparameters[\"min_child_weight\"] = min_child_weight\n",
        "# END - HYPERPARAMETER-DEPENDENT SECTION\n",
        "    for _ in range(n_experiments):\n",
        "        experiment_parameters[\"seed\"] = secrets.randbits(32)\n",
        "        train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.BoostedTrees, features, target, **experiment_parameters, hyperparameters=hyperparameters)\n",
        "        experiment_result = {\n",
        "            \"train_cv_mse\": train_cv_mse,\n",
        "            \"test_cv_mse\": test_cv_mse,\n",
        "        }\n",
        "        record = {\n",
        "            **experiment_parameters,\n",
        "            **hyperparameters,\n",
        "            **experiment_result,\n",
        "        }\n",
        "        experiment_records.append(record)\n",
        "end_time = time.time()\n",
        "print(f\"Duration of the experiment: {(end_time - start_time)/60:.1f} minutes.\")\n",
        "\n",
        "experiment_records = pd.DataFrame(experiment_records)"
      ],
      "metadata": {
        "id": "fkKLPhH2Jsnj",
        "outputId": "59533c2b-b561-496a-b1d3-61b60a64e9bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fkKLPhH2Jsnj",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration of the experiment: 1.4 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the RMSE for each set of hyperparameters (here, only the values of `max_depth` and `min_child_weight` change)\n",
        "np.sqrt(experiment_records.groupby(list(hyperparameters.keys()))[\"test_cv_mse\"].mean())"
      ],
      "metadata": {
        "id": "VXf6_2tNKdqK",
        "outputId": "d61f8111-70ba-4c3d-dfd8-7192cdd5dbd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        }
      },
      "id": "VXf6_2tNKdqK",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "n_estimators  gamma  subsample  colsample_bytree  scale_pos_weight  learning_rate  max_depth  min_child_weight\n",
              "100           0      0.8        0.8               1                 0.1            3          1                   128484.940657\n",
              "                                                                                              3                   130098.750255\n",
              "                                                                                              5                   132524.535200\n",
              "                                                                                   5          1                   127399.627202\n",
              "                                                                                              3                   126240.155417\n",
              "                                                                                              5                   134657.722118\n",
              "                                                                                   7          1                   129365.990649\n",
              "                                                                                              3                   133805.088515\n",
              "                                                                                              5                   133939.156881\n",
              "                                                                                   9          1                   134836.865910\n",
              "                                                                                              3                   136810.568275\n",
              "                                                                                              5                   136549.268537\n",
              "Name: test_cv_mse, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>test_cv_mse</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_estimators</th>\n",
              "      <th>gamma</th>\n",
              "      <th>subsample</th>\n",
              "      <th>colsample_bytree</th>\n",
              "      <th>scale_pos_weight</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_child_weight</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"12\" valign=\"top\">100</th>\n",
              "      <th rowspan=\"12\" valign=\"top\">0</th>\n",
              "      <th rowspan=\"12\" valign=\"top\">0.8</th>\n",
              "      <th rowspan=\"12\" valign=\"top\">0.8</th>\n",
              "      <th rowspan=\"12\" valign=\"top\">1</th>\n",
              "      <th rowspan=\"12\" valign=\"top\">0.1</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
              "      <th>1</th>\n",
              "      <td>128484.940657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>130098.750255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>132524.535200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
              "      <th>1</th>\n",
              "      <td>127399.627202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>126240.155417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>134657.722118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">7</th>\n",
              "      <th>1</th>\n",
              "      <td>129365.990649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>133805.088515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>133939.156881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">9</th>\n",
              "      <th>1</th>\n",
              "      <td>134836.865910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>136810.568275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>136549.268537</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: `gamma`"
      ],
      "metadata": {
        "id": "ETeHwZT0Ue1I"
      },
      "id": "ETeHwZT0Ue1I"
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3\n",
        "# We fix `max_depth = 5` and `min_child_weight = 3` from the previous step and\n",
        "# now seek to find a good value for `gamma`.\n",
        "hyperparameters = {\n",
        "    \"n_estimators\": 100,\n",
        "    \"max_depth\": 5,\n",
        "    \"min_child_weight\": 3,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"scale_pos_weight\": 1,\n",
        "    \"learning_rate\": 0.1\n",
        "}\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"seed\": None,\n",
        "    \"n_splits\": 10,\n",
        "}\n",
        "\n",
        "experiment_records = []\n",
        "n_experiments = 10\n",
        "start_time = time.time()\n",
        "# START - HYPERPARAMETER-DEPENDENT SECTION\n",
        "for gamma in (0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7):\n",
        "    hyperparameters[\"gamma\"] = gamma\n",
        "# END - HYPERPARAMETER-DEPENDENT SECTION\n",
        "    for _ in range(n_experiments):\n",
        "        experiment_parameters[\"seed\"] = secrets.randbits(32)\n",
        "        train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.BoostedTrees, features, target, **experiment_parameters, hyperparameters=hyperparameters)\n",
        "        experiment_result = {\n",
        "            \"train_cv_mse\": train_cv_mse,\n",
        "            \"test_cv_mse\": test_cv_mse,\n",
        "        }\n",
        "        record = {\n",
        "            **experiment_parameters,\n",
        "            **hyperparameters,\n",
        "            **experiment_result,\n",
        "        }\n",
        "        experiment_records.append(record)\n",
        "end_time = time.time()\n",
        "print(f\"Duration of the experiment: {(end_time - start_time)/60:.1f} minutes.\")\n",
        "\n",
        "experiment_records = pd.DataFrame(experiment_records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeIiO-3SSHNh",
        "outputId": "319df728-262c-4141-d1ba-53e8b2d0b902"
      },
      "id": "xeIiO-3SSHNh",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration of the experiment: 3.0 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the RMSE for each set of hyperparameters (here, only the value of `gamma` changes)\n",
        "np.sqrt(experiment_records.groupby(list(hyperparameters.keys()))[\"test_cv_mse\"].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "WDQn6sm8Sw9w",
        "outputId": "480424d0-37f0-41d6-b142-b905928e6478"
      },
      "id": "WDQn6sm8Sw9w",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "n_estimators  max_depth  min_child_weight  subsample  colsample_bytree  scale_pos_weight  learning_rate  gamma\n",
              "100           5          3                 0.8        0.8               1                 0.1            0.0      123956.596997\n",
              "                                                                                                         0.1      124706.825855\n",
              "                                                                                                         0.2      123208.149445\n",
              "                                                                                                         0.3      126462.903659\n",
              "                                                                                                         0.4      124128.959584\n",
              "                                                                                                         0.5      124574.191058\n",
              "                                                                                                         0.6      127750.085266\n",
              "                                                                                                         0.7      125643.084585\n",
              "Name: test_cv_mse, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>test_cv_mse</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_estimators</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_child_weight</th>\n",
              "      <th>subsample</th>\n",
              "      <th>colsample_bytree</th>\n",
              "      <th>scale_pos_weight</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>gamma</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"8\" valign=\"top\">100</th>\n",
              "      <th rowspan=\"8\" valign=\"top\">5</th>\n",
              "      <th rowspan=\"8\" valign=\"top\">3</th>\n",
              "      <th rowspan=\"8\" valign=\"top\">0.8</th>\n",
              "      <th rowspan=\"8\" valign=\"top\">0.8</th>\n",
              "      <th rowspan=\"8\" valign=\"top\">1</th>\n",
              "      <th rowspan=\"8\" valign=\"top\">0.1</th>\n",
              "      <th>0.0</th>\n",
              "      <td>123956.596997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.1</th>\n",
              "      <td>124706.825855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.2</th>\n",
              "      <td>123208.149445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.3</th>\n",
              "      <td>126462.903659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.4</th>\n",
              "      <td>124128.959584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.5</th>\n",
              "      <td>124574.191058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.6</th>\n",
              "      <td>127750.085266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7</th>\n",
              "      <td>125643.084585</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: `subsample` and `colsample_bytree`"
      ],
      "metadata": {
        "id": "dM8c1lUvUi-t"
      },
      "id": "dM8c1lUvUi-t"
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4\n",
        "# We fix `gamma = 0.2` from the previous step and\n",
        "# now seek to find good values for `subsample` and `colsample_bytree`.\n",
        "hyperparameters = {\n",
        "    \"n_estimators\": 100,\n",
        "    \"max_depth\": 5,\n",
        "    \"min_child_weight\": 3,\n",
        "    \"gamma\": 0.2,\n",
        "    \"scale_pos_weight\": 1,\n",
        "    \"learning_rate\": 0.1\n",
        "}\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"seed\": None,\n",
        "    \"n_splits\": 10,\n",
        "}\n",
        "\n",
        "experiment_records = []\n",
        "n_experiments = 10\n",
        "start_time = time.time()\n",
        "# START - HYPERPARAMETER-DEPENDENT SECTION\n",
        "for subsample, colsample_bytree in product((0.6, 0.7, 0.8, 0.9), (0.6, 0.7, 0.8, 0.9)):\n",
        "    hyperparameters[\"subsample\"] = subsample\n",
        "    hyperparameters[\"colsample_bytree\"] = colsample_bytree\n",
        "# END - HYPERPARAMETER-DEPENDENT SECTION\n",
        "    for _ in range(n_experiments):\n",
        "        experiment_parameters[\"seed\"] = secrets.randbits(32)\n",
        "        train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.BoostedTrees, features, target, **experiment_parameters, hyperparameters=hyperparameters)\n",
        "        experiment_result = {\n",
        "            \"train_cv_mse\": train_cv_mse,\n",
        "            \"test_cv_mse\": test_cv_mse,\n",
        "        }\n",
        "        record = {\n",
        "            **experiment_parameters,\n",
        "            **hyperparameters,\n",
        "            **experiment_result,\n",
        "        }\n",
        "        experiment_records.append(record)\n",
        "end_time = time.time()\n",
        "print(f\"Duration of the experiment: {(end_time - start_time)/60:.1f} minutes.\")\n",
        "\n",
        "experiment_records = pd.DataFrame(experiment_records)"
      ],
      "metadata": {
        "id": "VKgMI7bQUmOR",
        "outputId": "64565fa1-7001-489b-f8cf-070c6fb3dc10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VKgMI7bQUmOR",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration of the experiment: 5.8 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the RMSE for each set of hyperparameters (here, only the values of `subsample` and `colsample_bytree` change)\n",
        "np.sqrt(experiment_records.groupby(list(hyperparameters.keys()))[\"test_cv_mse\"].mean())"
      ],
      "metadata": {
        "id": "eJb665-MU8X2",
        "outputId": "abb92130-bd6b-4229-fc7d-34f4c559cc2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "id": "eJb665-MU8X2",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "n_estimators  max_depth  min_child_weight  gamma  scale_pos_weight  learning_rate  subsample  colsample_bytree\n",
              "100           5          3                 0.2    1                 0.1            0.6        0.6                 126372.267256\n",
              "                                                                                              0.7                 128550.076969\n",
              "                                                                                              0.8                 127118.054087\n",
              "                                                                                              0.9                 123376.361519\n",
              "                                                                                   0.7        0.6                 126324.033820\n",
              "                                                                                              0.7                 126534.710717\n",
              "                                                                                              0.8                 127830.026204\n",
              "                                                                                              0.9                 126192.150668\n",
              "                                                                                   0.8        0.6                 126254.005388\n",
              "                                                                                              0.7                 125544.839515\n",
              "                                                                                              0.8                 125300.547281\n",
              "                                                                                              0.9                 123655.189729\n",
              "                                                                                   0.9        0.6                 125568.709947\n",
              "                                                                                              0.7                 127960.407917\n",
              "                                                                                              0.8                 125855.508181\n",
              "                                                                                              0.9                 121671.781929\n",
              "Name: test_cv_mse, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>test_cv_mse</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_estimators</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_child_weight</th>\n",
              "      <th>gamma</th>\n",
              "      <th>scale_pos_weight</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>subsample</th>\n",
              "      <th>colsample_bytree</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"16\" valign=\"top\">100</th>\n",
              "      <th rowspan=\"16\" valign=\"top\">5</th>\n",
              "      <th rowspan=\"16\" valign=\"top\">3</th>\n",
              "      <th rowspan=\"16\" valign=\"top\">0.2</th>\n",
              "      <th rowspan=\"16\" valign=\"top\">1</th>\n",
              "      <th rowspan=\"16\" valign=\"top\">0.1</th>\n",
              "      <th rowspan=\"4\" valign=\"top\">0.6</th>\n",
              "      <th>0.6</th>\n",
              "      <td>126372.267256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7</th>\n",
              "      <td>128550.076969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.8</th>\n",
              "      <td>127118.054087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.9</th>\n",
              "      <td>123376.361519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">0.7</th>\n",
              "      <th>0.6</th>\n",
              "      <td>126324.033820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7</th>\n",
              "      <td>126534.710717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.8</th>\n",
              "      <td>127830.026204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.9</th>\n",
              "      <td>126192.150668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">0.8</th>\n",
              "      <th>0.6</th>\n",
              "      <td>126254.005388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7</th>\n",
              "      <td>125544.839515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.8</th>\n",
              "      <td>125300.547281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.9</th>\n",
              "      <td>123655.189729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">0.9</th>\n",
              "      <th>0.6</th>\n",
              "      <td>125568.709947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7</th>\n",
              "      <td>127960.407917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.8</th>\n",
              "      <td>125855.508181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.9</th>\n",
              "      <td>121671.781929</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: `reg_lambda`"
      ],
      "metadata": {
        "id": "jCz_hpVTXAhe"
      },
      "id": "jCz_hpVTXAhe"
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5\n",
        "# We fix `subsample = 0.6` and `colsample_bytree = 0.9` from the previous step and\n",
        "# now seek to find a good values for `reg_lambda`.\n",
        "hyperparameters = {\n",
        "    \"n_estimators\": 100,\n",
        "    \"max_depth\": 5,\n",
        "    \"min_child_weight\": 3,\n",
        "    \"gamma\": 0.2,\n",
        "    \"subsample\": 0.6,\n",
        "    \"colsample_bytree\": 0.9,\n",
        "    \"scale_pos_weight\": 1,\n",
        "    \"learning_rate\": 0.1\n",
        "}\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"seed\": None,\n",
        "    \"n_splits\": 10,\n",
        "}\n",
        "\n",
        "experiment_records = []\n",
        "n_experiments = 10\n",
        "start_time = time.time()\n",
        "# START - HYPERPARAMETER-DEPENDENT SECTION\n",
        "for reg_lambda in (0, 1e-5, 1e-4, 1e-3, 1e-2, 1, 10, 100):\n",
        "    hyperparameters[\"reg_lambda\"] = reg_lambda\n",
        "# END - HYPERPARAMETER-DEPENDENT SECTION\n",
        "    for _ in range(n_experiments):\n",
        "        experiment_parameters[\"seed\"] = secrets.randbits(32)\n",
        "        train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.BoostedTrees, features, target, **experiment_parameters, hyperparameters=hyperparameters)\n",
        "        experiment_result = {\n",
        "            \"train_cv_mse\": train_cv_mse,\n",
        "            \"test_cv_mse\": test_cv_mse,\n",
        "        }\n",
        "        record = {\n",
        "            **experiment_parameters,\n",
        "            **hyperparameters,\n",
        "            **experiment_result,\n",
        "        }\n",
        "        experiment_records.append(record)\n",
        "end_time = time.time()\n",
        "print(f\"Duration of the experiment: {(end_time - start_time)/60:.1f} minutes.\")\n",
        "\n",
        "experiment_records = pd.DataFrame(experiment_records)"
      ],
      "metadata": {
        "id": "qZuB3hIxXDBS",
        "outputId": "e077954f-ddc3-46f6-d697-9eb4e4c9a247",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qZuB3hIxXDBS",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration of the experiment: 3.0 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the RMSE for each set of hyperparameters (here, only the value of `reg_lambda` changes)\n",
        "np.sqrt(experiment_records.groupby(list(hyperparameters.keys()))[\"test_cv_mse\"].mean())"
      ],
      "metadata": {
        "id": "9uAcaJQqXIOE",
        "outputId": "abaf7503-9920-4ca0-825e-af1d229990fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "id": "9uAcaJQqXIOE",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "n_estimators  max_depth  min_child_weight  gamma  subsample  colsample_bytree  scale_pos_weight  learning_rate  reg_lambda\n",
              "100           5          3                 0.2    0.6        0.9               1                 0.1            0.00000       127015.200058\n",
              "                                                                                                                0.00001       125629.753419\n",
              "                                                                                                                0.00010       126045.717370\n",
              "                                                                                                                0.00100       123938.810957\n",
              "                                                                                                                0.01000       125735.006351\n",
              "                                                                                                                1.00000       122878.631742\n",
              "                                                                                                                10.00000      123679.489386\n",
              "                                                                                                                100.00000     149516.114355\n",
              "Name: test_cv_mse, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>test_cv_mse</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_estimators</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_child_weight</th>\n",
              "      <th>gamma</th>\n",
              "      <th>subsample</th>\n",
              "      <th>colsample_bytree</th>\n",
              "      <th>scale_pos_weight</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>reg_lambda</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"8\" valign=\"top\">100</th>\n",
              "      <th rowspan=\"8\" valign=\"top\">5</th>\n",
              "      <th rowspan=\"8\" valign=\"top\">3</th>\n",
              "      <th rowspan=\"8\" valign=\"top\">0.2</th>\n",
              "      <th rowspan=\"8\" valign=\"top\">0.6</th>\n",
              "      <th rowspan=\"8\" valign=\"top\">0.9</th>\n",
              "      <th rowspan=\"8\" valign=\"top\">1</th>\n",
              "      <th rowspan=\"8\" valign=\"top\">0.1</th>\n",
              "      <th>0.00000</th>\n",
              "      <td>127015.200058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.00001</th>\n",
              "      <td>125629.753419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.00010</th>\n",
              "      <td>126045.717370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.00100</th>\n",
              "      <td>123938.810957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.01000</th>\n",
              "      <td>125735.006351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.00000</th>\n",
              "      <td>122878.631742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.00000</th>\n",
              "      <td>123679.489386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100.00000</th>\n",
              "      <td>149516.114355</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Evaluate the final hyperparameter choice and train a final model"
      ],
      "metadata": {
        "id": "WNshakffZ37M"
      },
      "id": "WNshakffZ37M"
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {\n",
        "    \"max_depth\": 5,\n",
        "    \"min_child_weight\": 3,\n",
        "    \"gamma\": 0.2,\n",
        "    \"subsample\": 0.6,\n",
        "    \"colsample_bytree\": 0.9,\n",
        "    \"reg_lambda\": 0.001,\n",
        "    \"scale_pos_weight\": 1,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"n_estimators\": 5_000,\n",
        "}\n",
        "\n",
        "seed = secrets.randbits(32)\n",
        "\n",
        "start_time = time.time()\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.BoostedTrees, features, target, 100, seed, hyperparameters=hyperparameters)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "end_time = time.time()\n",
        "print(f\"Duration of the experiment: {(end_time - start_time)/60:.1f} minutes.\")\n",
        "\n",
        "# Report evaluations\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "id": "4ZAwUoSMZ7Xn",
        "outputId": "06d52bf2-e5a1-45e9-c5a2-cdf374c36e3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4ZAwUoSMZ7Xn",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration of the experiment: 13.0 minutes.\n",
            "Cross-validation training error: $14k\n",
            "Cross-validation test error:     $119k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model = models.BoostedTrees(**hyperparameters)\n",
        "model.fit(features, target)"
      ],
      "metadata": {
        "id": "nwZ1BlbjeB6_"
      },
      "id": "nwZ1BlbjeB6_",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(model.evaluate(features, target))"
      ],
      "metadata": {
        "id": "doX3W9XYealh",
        "outputId": "e43174d6-64b9-42af-e096-3f48712c3c87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "doX3W9XYealh",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(14189.633962861762)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model._model.save_model(\"xgb.model\")"
      ],
      "metadata": {
        "id": "j4bA4dXPeeHr",
        "outputId": "1e69e20d-012a-458f-df5c-b660e3a2980b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "j4bA4dXPeeHr",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/sklearn.py:1116: UserWarning: [16:53:57] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
            "  self.get_booster().save_model(fname)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model._model.load_model(\"xgb.model\")"
      ],
      "metadata": {
        "id": "WlTl6ZBHere7",
        "outputId": "1e8d7076-dacf-468b-cd18-732f4a1a619c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WlTl6ZBHere7",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/sklearn.py:1125: UserWarning: [16:54:48] WARNING: /workspace/src/c_api/c_api.cc:1511: Unknown file format: `model`. Using UBJSON (`ubj`) as a guess.\n",
            "  self.get_booster().load_model(fname)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(model.evaluate(features, target))"
      ],
      "metadata": {
        "id": "VTYcymVdevZR",
        "outputId": "03672ab9-2543-4d23-8d6b-8713725befb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VTYcymVdevZR",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(14189.633962861762)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}