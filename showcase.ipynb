{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad85b80b-8647-4d08-aff5-4d6a309c641d",
      "metadata": {
        "id": "ad85b80b-8647-4d08-aff5-4d6a309c641d"
      },
      "source": [
        "# HOPUS\n",
        "\n",
        "HOPUS (**HO**using **P**ricing **U**tilitie**S**) contains a variety of routines used to predict real estate prices.\n",
        "\n",
        "This notebook highlights what HOPUS can do, namely\n",
        "- clean the raw data,\n",
        "- train a variety of models for the prediction of real estate prices, and\n",
        "- evaluate the performance of these models."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Technical preliminaries"
      ],
      "metadata": {
        "id": "OEM9gL75m7Kt"
      },
      "id": "OEM9gL75m7Kt"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b98883a3-1533-4380-a6d1-03f601619bfe",
      "metadata": {
        "id": "b98883a3-1533-4380-a6d1-03f601619bfe",
        "outputId": "fd769083-e44a-4b5c-e7fb-e7a225574abf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hopus'...\n",
            "remote: Enumerating objects: 281, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 281 (delta 42), reused 31 (delta 12), pack-reused 204 (from 1)\u001b[K\n",
            "Receiving objects: 100% (281/281), 764.14 KiB | 2.28 MiB/s, done.\n",
            "Resolving deltas: 100% (151/151), done.\n",
            "/content/hopus\n"
          ]
        }
      ],
      "source": [
        "# We clone the HOPUS repository to have access to all its data and routines\n",
        "!git clone https://github.com/aremondtiedrez/hopus.git\n",
        "%cd hopus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import requisite modules from HOPUS\n",
        "import evaluation\n",
        "import models\n",
        "import preprocessing"
      ],
      "metadata": {
        "id": "2XeVMFJapR22"
      },
      "id": "2XeVMFJapR22",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data cleaning"
      ],
      "metadata": {
        "id": "062YLELMkks7"
      },
      "id": "062YLELMkks7"
    },
    {
      "cell_type": "code",
      "source": [
        "hpi = preprocessing.home_price_index.load()\n",
        "preprocessing.home_price_index.preprocess(hpi)\n",
        "\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)"
      ],
      "metadata": {
        "id": "g5fCLFiKkm0x"
      },
      "id": "g5fCLFiKkm0x",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_rmse = evaluation.hpi_rmse(listings_data, target=\"price\")\n",
        "log_price_rmse = evaluation.hpi_rmse(listings_data, target=\"logPrice\")\n",
        "print(\n",
        "    \"When using the available home price index\\n\"\n",
        "    \"instead of the true home price index,\\n\"\n",
        "    f\"the price RMSE is ${price_rmse/1_000:.0f}k and \\n\"\n",
        "    f\"the log-price RMSE is {log_price_rmse:.3f}.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfFHEMBmlzEq",
        "outputId": "0b9eee54-5873-437e-aff8-003c85094d17"
      },
      "id": "qfFHEMBmlzEq",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When using the available home price index\n",
            "instead of the true home price index,\n",
            "the price RMSE is $10k and \n",
            "the log-price RMSE is 0.021.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model\n",
        "Average (time-normalized) price-per-square-foot over each ZIP code"
      ],
      "metadata": {
        "id": "CJ10nY4KKs_d"
      },
      "id": "CJ10nY4KKs_d"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets"
      ],
      "metadata": {
        "id": "-wKqpNK-K3k2"
      },
      "id": "-wKqpNK-K3k2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.BaselineModel()\n",
        "model.fit(listings_data, None)\n",
        "train_mse = model.evaluate(listings_data, listings_data[\"price\"])\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "print(f\"Training error: ${train_rmse / 1_000:.3f}k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tokBPzGDULm-",
        "outputId": "f1882ee8-d346-4149-8e55-cc89c4a441aa"
      },
      "id": "tokBPzGDULm-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training error: $157.830k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = secrets.randbits(32)\n",
        "\n",
        "# Group columns first to define feature sets\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegressionModel, listings_data[\"keyPredictionFeatures\"], listings_data[\"price\"], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "# Report evaluations\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3NsDz0VaXOm",
        "outputId": "cfe8f498-5610-4fbe-c223-9b830e06a26a"
      },
      "id": "_3NsDz0VaXOm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation training error: $158k\n",
            "Cross-validation test error:     $159k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Technical preliminary (before linear regression or XGBoost)\n",
        "We group the columns into key features, auxiliary features, and target\n",
        "(as well as into information columns and unused columns)."
      ],
      "metadata": {
        "id": "NaNmqrnQT6Y-"
      },
      "id": "NaNmqrnQT6Y-"
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing.property_listings.group_columns(listings_data)"
      ],
      "metadata": {
        "id": "jFKNTHRlT6sr"
      },
      "id": "jFKNTHRlT6sr",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression: training and evaluation"
      ],
      "metadata": {
        "id": "x67uIijqBxQu"
      },
      "id": "x67uIijqBxQu"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "oMJRfFuNf2Nd"
      },
      "id": "oMJRfFuNf2Nd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = secrets.randbits(32)\n",
        "\n",
        "# Train-test split\n",
        "train_features, test_features = train_test_split(listings_data[\"keyPredictionFeatures\"], train_size=0.8, shuffle=True, random_state=seed)\n",
        "train_target, test_target = train_test_split(listings_data[(\"target\", \"price\")], train_size=0.8, shuffle=True, random_state=seed)\n",
        "\n",
        "# Train model\n",
        "model = models.LinearRegressionModel()\n",
        "model.fit(train_features, train_target)\n",
        "\n",
        "# Evaluate model\n",
        "train_rmse = np.sqrt(model.evaluate(train_features, train_target))\n",
        "test_rmse = np.sqrt(model.evaluate(test_features, test_target))\n",
        "\n",
        "# Report evaluations\n",
        "print(f\"Seed: {seed}\")\n",
        "print(f\"Training error: ${train_rmse / 1_000:.3f}k\")\n",
        "print(f\"Test error:     ${test_rmse / 1_000:.3f}k\")"
      ],
      "metadata": {
        "id": "dsdAoBR5B-WZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e299357-02d2-4541-8cca-e319c33bc11d"
      },
      "id": "dsdAoBR5B-WZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed: 2492155124\n",
            "Training error: $153.731k\n",
            "Test error:     $165.795k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression: evaluation with cross-validation"
      ],
      "metadata": {
        "id": "IJOAf4QFMzcm"
      },
      "id": "IJOAf4QFMzcm"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets"
      ],
      "metadata": {
        "id": "5xdVLh7KM3H5"
      },
      "id": "5xdVLh7KM3H5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = secrets.randbits(32)\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegressionModel, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "# Report evaluations\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd-OyngegV2O",
        "outputId": "fdabdf2d-9bc9-4244-92ed-c53ee19548a2"
      },
      "id": "kd-OyngegV2O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation training error: $156k\n",
            "Cross-validation test error:     $160k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression: cross-validation for various data subsets"
      ],
      "metadata": {
        "id": "PUmaN8fUjznV"
      },
      "id": "PUmaN8fUjznV"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets"
      ],
      "metadata": {
        "id": "1mKIViookDAq"
      },
      "id": "1mKIViookDAq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = secrets.randbits(32)"
      ],
      "metadata": {
        "id": "tuSVNuXoqcZy"
      },
      "id": "tuSVNuXoqcZy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# PART A: USING ONLY THE KEY PREDICTION FEATURES\n",
        "# --------------------------------------------------\n",
        "\n",
        "# Case 1: with outliers and imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "#preprocessing.property_listings.drop_outliers(listings_data)\n",
        "#preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegressionModel, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"With outliers and with imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 2: without outliers but with imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "#preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegressionModel, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Without outliers but with imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 3: with outliers but without imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "#preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegressionModel, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"With outliers but without imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 1: without outliers nor imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegressionModel, listings_data[\"keyPredictionFeatures\"], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Without outliers nor imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "id": "3XfrBstwjzCl",
        "outputId": "fa694a9e-746f-4ce1-9160-df4c87ca73cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3XfrBstwjzCl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "With outliers and with imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $248k\n",
            "Cross-validation test error:     $252k\n",
            "--------------------------------------------------\n",
            "Without outliers but with imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $163k\n",
            "Cross-validation test error:     $168k\n",
            "--------------------------------------------------\n",
            "With outliers but without imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $240k\n",
            "Cross-validation test error:     $244k\n",
            "--------------------------------------------------\n",
            "Without outliers nor imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $156k\n",
            "Cross-validation test error:     $160k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# PART B: USING THE KEY AND THE AUXILIARY PREDICTION FEATURES\n",
        "# ------------------------------------------------------------\n",
        "features_label = [\"keyPredictionFeatures\", \"auxiliaryPredictionFeatures\"]\n",
        "\n",
        "# Case 1: with outliers and imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "#preprocessing.property_listings.drop_outliers(listings_data)\n",
        "#preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegressionModel, listings_data[features_label], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"With outliers and with imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 2: without outliers but with imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "#preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegressionModel, listings_data[features_label], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Without outliers but with imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 3: with outliers but without imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "#preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegressionModel, listings_data[features_label], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"With outliers but without imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")\n",
        "\n",
        "# Case 1: without outliers nor imperfect samples\n",
        "listings_data = preprocessing.property_listings.load()\n",
        "listings_data = preprocessing.property_listings.preprocess(listings_data, hpi)\n",
        "\n",
        "preprocessing.property_listings.drop_outliers(listings_data)\n",
        "preprocessing.property_listings.drop_missing_key_features(listings_data)\n",
        "\n",
        "preprocessing.property_listings.group_columns(listings_data)\n",
        "\n",
        "train_cv_mse, test_cv_mse, trained_models = evaluation.cv_evaluation(models.LinearRegressionModel, listings_data[features_label], listings_data[(\"target\", \"price\")], 100, seed)\n",
        "train_cv_rmse, test_cv_rmse = np.sqrt(np.array([train_cv_mse, test_cv_mse]))\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Without outliers nor imperfect samples.\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Cross-validation training error: ${train_cv_rmse / 1_000:.0f}k\")\n",
        "print(f\"Cross-validation test error:     ${test_cv_rmse / 1_000:.0f}k\")"
      ],
      "metadata": {
        "id": "kW4SSYAvqhnc",
        "outputId": "72d88f4d-5295-4f51-ef6c-1ee8a1dd9c75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kW4SSYAvqhnc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "With outliers and with imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $230k\n",
            "Cross-validation test error:     $248k\n",
            "--------------------------------------------------\n",
            "Without outliers but with imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $144k\n",
            "Cross-validation test error:     $161k\n",
            "--------------------------------------------------\n",
            "With outliers but without imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $227k\n",
            "Cross-validation test error:     $240k\n",
            "--------------------------------------------------\n",
            "Without outliers nor imperfect samples.\n",
            "--------------------------------------------------\n",
            "Cross-validation training error: $138k\n",
            "Cross-validation test error:     $152k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "ie8WmxhcGWsC"
      },
      "id": "ie8WmxhcGWsC"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import secrets\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor"
      ],
      "metadata": {
        "id": "js4fCZ0PGxwi"
      },
      "id": "js4fCZ0PGxwi",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = secrets.randbits(32)\n",
        "\n",
        "# Set hyperparameters\n",
        "hyperparameters = {\n",
        "    \"max_depth\": 5,\n",
        "    \"min_child_weight\": 1,\n",
        "    \"gamma\": 0,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"scale_pos_weight\": 1\n",
        "}\n",
        "\n",
        "# Train-test split\n",
        "train_features, test_features = train_test_split(listings_data[[\"keyPredictionFeatures\", \"auxiliaryPredictionFeatures\"]], train_size=0.8, shuffle=True, random_state=seed)\n",
        "train_target, test_target = train_test_split(listings_data[(\"target\", \"price\")], train_size=0.8, shuffle=True, random_state=seed)\n",
        "\n",
        "# Train model\n",
        "model = XGBRegressor(**hyperparameters)\n",
        "model.fit(train_features, train_target, eval_set=[(test_features, test_target)], verbose=False)\n",
        "\n",
        "# Evaluate model\n",
        "train_predictions = model.predict(train_features)\n",
        "test_predictions = model.predict(test_features)\n",
        "\n",
        "train_rmse = np.sqrt(mean_squared_error(train_target, train_predictions))\n",
        "test_rmse = np.sqrt(mean_squared_error(test_target, test_predictions))\n",
        "\n",
        "# Report evaluations\n",
        "print(f\"Seed: {seed}\")\n",
        "print(f\"Training error: ${train_rmse / 1_000:.3f}k\")\n",
        "print(f\"Test error:     ${test_rmse / 1_000:.3f}k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o54uc4jG-kj",
        "outputId": "f26d7ae7-3893-4fe0-841b-3e55bb3486cd"
      },
      "id": "8o54uc4jG-kj",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed: 2191346635\n",
            "Training error: $21.342k\n",
            "Test error:     $133.301k\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}